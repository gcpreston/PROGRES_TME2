{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "294988a5",
   "metadata": {},
   "source": [
    "# PROGRES - TME2\n",
    "\n",
    "Fabien Mathieu - fabien.mathieu@normalesup.org\n",
    "\n",
    "Sébastien Tixeuil - Sebastien.Tixeuil@lip6.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9046b32",
   "metadata": {},
   "source": [
    "**Note**: \n",
    "- Star exercises (indicated by *) should only be done if all other exercises have been completed. You \n",
    "don't have to do them if you do not want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495b0fc5",
   "metadata": {},
   "source": [
    "# Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f73082",
   "metadata": {},
   "source": [
    "1. Cite your sources\n",
    "2. One file to rule them all\n",
    "3. Explain\n",
    "4. Execute your code\n",
    "\n",
    "\n",
    "https://github.com/balouf/progres/blob/main/rules.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01a42a0",
   "metadata": {},
   "source": [
    "# Exercice 1 - Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777c51e",
   "metadata": {},
   "source": [
    "Consider the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd42208b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.166734Z",
     "start_time": "2024-10-11T07:03:31.162693Z"
    }
   },
   "outputs": [],
   "source": [
    "L = ['marie.Dupond@gmail.com', 'lucie.Durand@wanadoo.fr',\n",
    "'Sophie.Parmentier @@ gmail.com', 'franck.Dupres.gmail.com',\n",
    "'pierre.Martin@lip6 .fr ',' eric.Deschamps@gmail.com ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d522f37b",
   "metadata": {},
   "source": [
    "- Which of these entries are valid?\n",
    "- Use regular expressions to identify valid *gmail* addresses and display them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031d815",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f803bc",
   "metadata": {},
   "source": [
    "The valid entries are `'marie.Dupond@gmail.com'`, `' eric.Deschamps@gmail.com '`. We consider otherwise valid strings which are whitespace-padded to also be valid, as stripping is a simple operation, and this lends itself to a better user experience (if the user doesn't realize there is an invisible space, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e58857cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.182237Z",
     "start_time": "2024-10-11T07:03:31.167743Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import functools\n",
    "from typing import List\n",
    "\n",
    "GMAIL_RE = re.compile(r'^\\s*([0-9A-Za-z_.]+@gmail.com)\\s*')\n",
    "\n",
    "def _true_gmail_reducer(accumulator: List[str], test_address: str) -> bool:\n",
    "    gmail_match = GMAIL_RE.match(test_address)\n",
    "    if not gmail_match: return accumulator\n",
    "    address = gmail_match.group(1)\n",
    "    return accumulator + [address]\n",
    "\n",
    "def true_gmail(mail_list: List[str]) -> List[str]:\n",
    "    return functools.reduce(_true_gmail_reducer, mail_list, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2496b3",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The `true_gmail` transforms a list of strings to a list of found, whitespace-stripped, gmail addresses. Because values of the output list may be transformed from those of the input list, a `reduce` is used in place of a `filter`. \n",
    "\n",
    "The reducer implements the logic. It tests against a gmail regex and implements two cases:\n",
    "1. If there is no match, throw out the address by returning the unchanged accumulator\n",
    "2. Otherwise, continue to the next iteration with the desired portion of the address, by returning the accumulator with the address portion appended\n",
    "\n",
    "Note that `+` is used for list extension rather than `.append`. This is to prevent any unexpected behavior that could come from mutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "816fd798",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.210273Z",
     "start_time": "2024-10-11T07:03:31.196497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marie.Dupond@gmail.com', 'eric.Deschamps@gmail.com']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_gmail(L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5375b8f3",
   "metadata": {},
   "source": [
    "- Use regular expressions to check if a string ends with a number. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c3615",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13acfb67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.221802Z",
     "start_time": "2024-10-11T07:03:31.211282Z"
    }
   },
   "outputs": [],
   "source": [
    "def ends_with_number(txt: str) -> bool:\n",
    "    return bool(re.match(r'^.*\\d$', txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef169126",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "`ends_with_number` checks for a match of the given parameter against the regular expression `^.*\\d$`. The regular expression could be worded in English as: \"match anything from the beginning of the string, then match a number followed by the string end\".\n",
    "\n",
    "`re.match` returns a `Match` object if a match is present, and `None` otherwise, but `ends_with_number` wants to return a boolean indicating yes or no. The result of `re.match` is transformed to the desired output by simply being passed to `bool`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9da640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.246076Z",
     "start_time": "2024-10-11T07:03:31.235381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_with_number('to42to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aa5f293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.257782Z",
     "start_time": "2024-10-11T07:03:31.248084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_with_number('to42to666')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bde5d7",
   "metadata": {},
   "source": [
    "- Use regular expressions to remove problematic zeros from an IPv4 address expressed as a \n",
    "string. (example: \"216.08.094.196\" should become \"216.8.94.196\", but \"216.80.140.196\" \n",
    "should remain \"216.80.140.196\"). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f606b5",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d2f77ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.271323Z",
     "start_time": "2024-10-11T07:03:31.261798Z"
    }
   },
   "outputs": [],
   "source": [
    "IPV4_FIELD_RE = re.compile(r'0*(\\d{1,3})')\n",
    "\n",
    "def normalize_ip(txt):\n",
    "    return '.'.join(IPV4_FIELD_RE.findall(txt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f5056",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "`normalize_ip` uses a regular expression to match the desired substring for each sequence within an IPv4 address. The list of desired sequences is taken using `.findall`, which is then re-formatted to an IPv4 string using `'.'.join`. \n",
    "\n",
    "The regular expression used is `0*(\\d{1,3})`. There are two parts to this expression:\n",
    "1. `0*` matches 0 or more of the character `0`, at the beginning of the sequence, outside the capture group\n",
    "2. `(\\d{1,3})` matches 1-3 digits in a row for a sequence, and puts them in a capture group\n",
    "\n",
    "The first part enables excluding leading `0`s from the capture group, while not requiring leading `0`s to match. The second part matching at least 1 digit enables capturing a `0` if it is the actual value of the sequence. e.g: The edge case `'000'` matches only the last `0` within the capture group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "088d349e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.295246Z",
     "start_time": "2024-10-11T07:03:31.284633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.0.94.196'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_ip(\"216.0.094.196\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c2cb4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.309262Z",
     "start_time": "2024-10-11T07:03:31.296255Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.8.94.196'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_ip(\"216.08.094.196\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b6be3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.350525Z",
     "start_time": "2024-10-11T07:03:31.313271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216.80.140.196'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_ip(\"216.80.140.196\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8ac9d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.0.0.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_ip(\"000.00.0.000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defac980",
   "metadata": {},
   "source": [
    "- Use regular expressions to transform a date from MM-DD-YYYY format to DD-MM-YYYY \n",
    "format. (example \"11-06-2020\" should become \"06-11-2020\"). Optionally*, do the same thing using the `datetime` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c7974",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01892f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.360858Z",
     "start_time": "2024-10-11T07:03:31.356546Z"
    }
   },
   "outputs": [],
   "source": [
    "DATE_RE = re.compile(r'^(\\d{2})-(\\d{2})-(\\d{4})$')\n",
    "\n",
    "def switch_md(txt: str) -> str:\n",
    "    mm, dd, yyyy = DATE_RE.match(txt).groups()\n",
    "    return '-'.join([dd, mm, yyyy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c93b73",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "`switch_md` uses a regex to match a full date string and grab groups of each section, then re-orders and re-joins them to the desired format.\n",
    "\n",
    "Note that it is assumed the `txt` parameter matches this format, and does not define behavior for when this is not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f731cbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.399470Z",
     "start_time": "2024-10-11T07:03:31.386752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06-11-2020'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "switch_md(\"11-06-2020\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1a107",
   "metadata": {},
   "source": [
    "# Exercice 2 - Analyze XML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a77fec",
   "metadata": {},
   "source": [
    "- Write a Python code that retrieves the content of the page at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a640a342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.410291Z",
     "start_time": "2024-10-11T07:03:31.400475Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://www.w3schools.com/xml/cd_catalog.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2670c999",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import Session\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "s = Session()\n",
    "r = s.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ff873",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "To retrieve the URL content, `Sessions.get` is used, to give the option to keep cookies and re-use a TCP connection if we were making multiple requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c371f1f2",
   "metadata": {},
   "source": [
    "- Look at the text content and load as xml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c5d366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<CATALOG>\n",
      "  <CD>\n",
      "    <TITLE>Empire Burlesque</TITLE>\n",
      "    <ARTIST>Bob Dylan</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Columbia</COMPANY>\n",
      "    <PRICE>10.90</PRICE>\n",
      "    <YEAR>1985</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Hide your heart</TITLE>\n",
      "    <ARTIST>Bonnie Tyler</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>CBS Records</COMPANY>\n",
      "    <PRICE>9.90</PRICE>\n",
      "    <YEAR>1988</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Greatest Hits</TITLE>\n",
      "    <ARTIST>Dolly Parton</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>RCA</COMPANY>\n",
      "    <PRICE>9.90</PRICE>\n",
      "    <YEAR>1982</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Still got the blues</TITLE>\n",
      "    <ARTIST>Gary Moore</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Virgin records</COMPANY>\n",
      "    <PRICE>10.20</PRICE>\n",
      "    <YEAR>1990</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Eros</TITLE>\n",
      "    <ARTIST>Eros Ramazzotti</ARTIST>\n",
      "    <COUNTRY>EU</COUNTRY>\n",
      "    <COMPANY>BMG</COMPANY>\n",
      "    <PRICE>9.90</PRICE>\n",
      "    <YEAR>1997</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>One night only</TITLE>\n",
      "    <ARTIST>Bee Gees</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Polydor</COMPANY>\n",
      "    <PRICE>10.90</PRICE>\n",
      "    <YEAR>1998</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Sylvias Mother</TITLE>\n",
      "    <ARTIST>Dr.Hook</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>CBS</COMPANY>\n",
      "    <PRICE>8.10</PRICE>\n",
      "    <YEAR>1973</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Maggie May</TITLE>\n",
      "    <ARTIST>Rod Stewart</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Pickwick</COMPANY>\n",
      "    <PRICE>8.50</PRICE>\n",
      "    <YEAR>1990</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Romanza</TITLE>\n",
      "    <ARTIST>Andrea Bocelli</ARTIST>\n",
      "    <COUNTRY>EU</COUNTRY>\n",
      "    <COMPANY>Polydor</COMPANY>\n",
      "    <PRICE>10.80</PRICE>\n",
      "    <YEAR>1996</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>When a man loves a woman</TITLE>\n",
      "    <ARTIST>Percy Sledge</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Atlantic</COMPANY>\n",
      "    <PRICE>8.70</PRICE>\n",
      "    <YEAR>1987</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Black angel</TITLE>\n",
      "    <ARTIST>Savage Rose</ARTIST>\n",
      "    <COUNTRY>EU</COUNTRY>\n",
      "    <COMPANY>Mega</COMPANY>\n",
      "    <PRICE>10.90</PRICE>\n",
      "    <YEAR>1995</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>1999 Grammy Nominees</TITLE>\n",
      "    <ARTIST>Many</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Grammy</COMPANY>\n",
      "    <PRICE>10.20</PRICE>\n",
      "    <YEAR>1999</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>For the good times</TITLE>\n",
      "    <ARTIST>Kenny Rogers</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Mucik Master</COMPANY>\n",
      "    <PRICE>8.70</PRICE>\n",
      "    <YEAR>1995</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Big Willie style</TITLE>\n",
      "    <ARTIST>Will Smith</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Columbia</COMPANY>\n",
      "    <PRICE>9.90</PRICE>\n",
      "    <YEAR>1997</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Tupelo Honey</TITLE>\n",
      "    <ARTIST>Van Morrison</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Polydor</COMPANY>\n",
      "    <PRICE>8.20</PRICE>\n",
      "    <YEAR>1971</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Soulsville</TITLE>\n",
      "    <ARTIST>Jorn Hoel</ARTIST>\n",
      "    <COUNTRY>Norway</COUNTRY>\n",
      "    <COMPANY>WEA</COMPANY>\n",
      "    <PRICE>7.90</PRICE>\n",
      "    <YEAR>1996</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>The very best of</TITLE>\n",
      "    <ARTIST>Cat Stevens</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Island</COMPANY>\n",
      "    <PRICE>8.90</PRICE>\n",
      "    <YEAR>1990</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Stop</TITLE>\n",
      "    <ARTIST>Sam Brown</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>A and M</COMPANY>\n",
      "    <PRICE>8.90</PRICE>\n",
      "    <YEAR>1988</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Bridge of Spies</TITLE>\n",
      "    <ARTIST>T'Pau</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Siren</COMPANY>\n",
      "    <PRICE>7.90</PRICE>\n",
      "    <YEAR>1987</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Private Dancer</TITLE>\n",
      "    <ARTIST>Tina Turner</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>Capitol</COMPANY>\n",
      "    <PRICE>8.90</PRICE>\n",
      "    <YEAR>1983</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Midt om natten</TITLE>\n",
      "    <ARTIST>Kim Larsen</ARTIST>\n",
      "    <COUNTRY>EU</COUNTRY>\n",
      "    <COMPANY>Medley</COMPANY>\n",
      "    <PRICE>7.80</PRICE>\n",
      "    <YEAR>1983</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Pavarotti Gala Concert</TITLE>\n",
      "    <ARTIST>Luciano Pavarotti</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>DECCA</COMPANY>\n",
      "    <PRICE>9.90</PRICE>\n",
      "    <YEAR>1991</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>The dock of the bay</TITLE>\n",
      "    <ARTIST>Otis Redding</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>Stax Records</COMPANY>\n",
      "    <PRICE>7.90</PRICE>\n",
      "    <YEAR>1968</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Picture book</TITLE>\n",
      "    <ARTIST>Simply Red</ARTIST>\n",
      "    <COUNTRY>EU</COUNTRY>\n",
      "    <COMPANY>Elektra</COMPANY>\n",
      "    <PRICE>7.20</PRICE>\n",
      "    <YEAR>1985</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Red</TITLE>\n",
      "    <ARTIST>The Communards</ARTIST>\n",
      "    <COUNTRY>UK</COUNTRY>\n",
      "    <COMPANY>London</COMPANY>\n",
      "    <PRICE>7.80</PRICE>\n",
      "    <YEAR>1987</YEAR>\n",
      "  </CD>\n",
      "  <CD>\n",
      "    <TITLE>Unchain my heart</TITLE>\n",
      "    <ARTIST>Joe Cocker</ARTIST>\n",
      "    <COUNTRY>USA</COUNTRY>\n",
      "    <COMPANY>EMI</COMPANY>\n",
      "    <PRICE>8.20</PRICE>\n",
      "    <YEAR>1987</YEAR>\n",
      "  </CD>\n",
      "</CATALOG>\n",
      "\n",
      "Main tag: CATALOG; main attributes: {}\n"
     ]
    }
   ],
   "source": [
    "print(r.text)\n",
    "cds = ET.fromstring(r.text)\n",
    "print(f\"Main tag: {cds.tag}; main attributes: {cds.attrib}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb1cdc",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "To load the result as XML, `ElementTree.fromstring` is used, for simplicity's sake."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4d26eb",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ed90b",
   "metadata": {},
   "source": [
    "- Write a `display_cd` function that displays (i.e. `print`), for a CD: title, artist, country, company, year.\n",
    "- Display all CDs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c1c3b4",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee85351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.730469Z",
     "start_time": "2024-10-11T07:03:31.712761Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_cd(cd: ET) -> None:\n",
    "    properties = [f'{child.tag}: {child.text}' for child in cd]\n",
    "    print(', '.join(properties))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e934cb66",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The chosen format for displaying a CD is to display all child tags and their text content, separated by commas. This is done by first creating a list of tags + values with the desired format, and then utilizing `.join` to easily intersperse commas, and printing the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c94c7d5",
   "metadata": {},
   "source": [
    "- Display all 1980s CDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f548d865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Empire Burlesque, ARTIST: Bob Dylan, COUNTRY: USA, COMPANY: Columbia, PRICE: 10.90, YEAR: 1985\n",
      "TITLE: Hide your heart, ARTIST: Bonnie Tyler, COUNTRY: UK, COMPANY: CBS Records, PRICE: 9.90, YEAR: 1988\n",
      "TITLE: Greatest Hits, ARTIST: Dolly Parton, COUNTRY: USA, COMPANY: RCA, PRICE: 9.90, YEAR: 1982\n",
      "TITLE: Still got the blues, ARTIST: Gary Moore, COUNTRY: UK, COMPANY: Virgin records, PRICE: 10.20, YEAR: 1990\n",
      "TITLE: Eros, ARTIST: Eros Ramazzotti, COUNTRY: EU, COMPANY: BMG, PRICE: 9.90, YEAR: 1997\n",
      "TITLE: One night only, ARTIST: Bee Gees, COUNTRY: UK, COMPANY: Polydor, PRICE: 10.90, YEAR: 1998\n",
      "TITLE: Sylvias Mother, ARTIST: Dr.Hook, COUNTRY: UK, COMPANY: CBS, PRICE: 8.10, YEAR: 1973\n",
      "TITLE: Maggie May, ARTIST: Rod Stewart, COUNTRY: UK, COMPANY: Pickwick, PRICE: 8.50, YEAR: 1990\n",
      "TITLE: Romanza, ARTIST: Andrea Bocelli, COUNTRY: EU, COMPANY: Polydor, PRICE: 10.80, YEAR: 1996\n",
      "TITLE: When a man loves a woman, ARTIST: Percy Sledge, COUNTRY: USA, COMPANY: Atlantic, PRICE: 8.70, YEAR: 1987\n",
      "TITLE: Black angel, ARTIST: Savage Rose, COUNTRY: EU, COMPANY: Mega, PRICE: 10.90, YEAR: 1995\n",
      "TITLE: 1999 Grammy Nominees, ARTIST: Many, COUNTRY: USA, COMPANY: Grammy, PRICE: 10.20, YEAR: 1999\n",
      "TITLE: For the good times, ARTIST: Kenny Rogers, COUNTRY: UK, COMPANY: Mucik Master, PRICE: 8.70, YEAR: 1995\n",
      "TITLE: Big Willie style, ARTIST: Will Smith, COUNTRY: USA, COMPANY: Columbia, PRICE: 9.90, YEAR: 1997\n",
      "TITLE: Tupelo Honey, ARTIST: Van Morrison, COUNTRY: UK, COMPANY: Polydor, PRICE: 8.20, YEAR: 1971\n",
      "TITLE: Soulsville, ARTIST: Jorn Hoel, COUNTRY: Norway, COMPANY: WEA, PRICE: 7.90, YEAR: 1996\n",
      "TITLE: The very best of, ARTIST: Cat Stevens, COUNTRY: UK, COMPANY: Island, PRICE: 8.90, YEAR: 1990\n",
      "TITLE: Stop, ARTIST: Sam Brown, COUNTRY: UK, COMPANY: A and M, PRICE: 8.90, YEAR: 1988\n",
      "TITLE: Bridge of Spies, ARTIST: T'Pau, COUNTRY: UK, COMPANY: Siren, PRICE: 7.90, YEAR: 1987\n",
      "TITLE: Private Dancer, ARTIST: Tina Turner, COUNTRY: UK, COMPANY: Capitol, PRICE: 8.90, YEAR: 1983\n",
      "TITLE: Midt om natten, ARTIST: Kim Larsen, COUNTRY: EU, COMPANY: Medley, PRICE: 7.80, YEAR: 1983\n",
      "TITLE: Pavarotti Gala Concert, ARTIST: Luciano Pavarotti, COUNTRY: UK, COMPANY: DECCA, PRICE: 9.90, YEAR: 1991\n",
      "TITLE: The dock of the bay, ARTIST: Otis Redding, COUNTRY: USA, COMPANY: Stax Records, PRICE: 7.90, YEAR: 1968\n",
      "TITLE: Picture book, ARTIST: Simply Red, COUNTRY: EU, COMPANY: Elektra, PRICE: 7.20, YEAR: 1985\n",
      "TITLE: Red, ARTIST: The Communards, COUNTRY: UK, COMPANY: London, PRICE: 7.80, YEAR: 1987\n",
      "TITLE: Unchain my heart, ARTIST: Joe Cocker, COUNTRY: USA, COMPANY: EMI, PRICE: 8.20, YEAR: 1987\n"
     ]
    }
   ],
   "source": [
    "for cd in cds:\n",
    "  display_cd(cd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73709331",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The root element has CDs as sub-elements. Since `display_cd` expects a single CD record, we iterate through the root and pass each child to `display_cd`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d207ba3",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d395138d",
   "metadata": {},
   "source": [
    "- Display all British CDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d7efe29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE: Hide your heart, ARTIST: Bonnie Tyler, COUNTRY: UK, COMPANY: CBS Records, PRICE: 9.90, YEAR: 1988\n",
      "TITLE: Still got the blues, ARTIST: Gary Moore, COUNTRY: UK, COMPANY: Virgin records, PRICE: 10.20, YEAR: 1990\n",
      "TITLE: One night only, ARTIST: Bee Gees, COUNTRY: UK, COMPANY: Polydor, PRICE: 10.90, YEAR: 1998\n",
      "TITLE: Sylvias Mother, ARTIST: Dr.Hook, COUNTRY: UK, COMPANY: CBS, PRICE: 8.10, YEAR: 1973\n",
      "TITLE: Maggie May, ARTIST: Rod Stewart, COUNTRY: UK, COMPANY: Pickwick, PRICE: 8.50, YEAR: 1990\n",
      "TITLE: For the good times, ARTIST: Kenny Rogers, COUNTRY: UK, COMPANY: Mucik Master, PRICE: 8.70, YEAR: 1995\n",
      "TITLE: Tupelo Honey, ARTIST: Van Morrison, COUNTRY: UK, COMPANY: Polydor, PRICE: 8.20, YEAR: 1971\n",
      "TITLE: The very best of, ARTIST: Cat Stevens, COUNTRY: UK, COMPANY: Island, PRICE: 8.90, YEAR: 1990\n",
      "TITLE: Stop, ARTIST: Sam Brown, COUNTRY: UK, COMPANY: A and M, PRICE: 8.90, YEAR: 1988\n",
      "TITLE: Bridge of Spies, ARTIST: T'Pau, COUNTRY: UK, COMPANY: Siren, PRICE: 7.90, YEAR: 1987\n",
      "TITLE: Private Dancer, ARTIST: Tina Turner, COUNTRY: UK, COMPANY: Capitol, PRICE: 8.90, YEAR: 1983\n",
      "TITLE: Pavarotti Gala Concert, ARTIST: Luciano Pavarotti, COUNTRY: UK, COMPANY: DECCA, PRICE: 9.90, YEAR: 1991\n",
      "TITLE: Red, ARTIST: The Communards, COUNTRY: UK, COMPANY: London, PRICE: 7.80, YEAR: 1987\n"
     ]
    }
   ],
   "source": [
    "british_cds = cds.findall(\"CD[COUNTRY='UK']\")\n",
    "for bcd in british_cds:\n",
    "  display_cd(bcd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a05f0b",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "This code uses XPath to find all British CDs. It does this by selecting all `CD` tags which have a sub-tag `COUNTRY` with the text value `UK`.\n",
    "\n",
    "Reference: [XPath section of the ElementTree docs](https://docs.python.org/3/library/xml.etree.elementtree.html#xpath-support)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae63660b",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dda5235",
   "metadata": {},
   "source": [
    "# Exercice 3 - Analyze JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b24d30",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    }
   },
   "source": [
    "- Write a Python program that gets the file of filming locations in Paris at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de719209",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:31.786738Z",
     "start_time": "2024-10-11T07:03:31.778307Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://opendata.paris.fr/explore/dataset/lieux-de-tournage-a-paris/download/?format=json&timezone=Europe/Berlin&lang=fr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343174e2",
   "metadata": {},
   "source": [
    "- How many entries have you got?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3e1f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'opendata.paris.fr'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entry count: 12265\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def download(source_url, dest_file):\n",
    "  s = Session()\n",
    "  s.verify = False\n",
    "  r = s.get(source_url, stream=True)\n",
    "  dest_file = Path(dest_file)\n",
    "\n",
    "  with open(dest_file, 'wb') as f:\n",
    "    for chunk in r.iter_content(chunk_size=8192):\n",
    "      if chunk:\n",
    "        f.write(chunk)\n",
    "\n",
    "FN = 'tournage.json'\n",
    "download(url, FN)\n",
    "\n",
    "with open(FN) as f:\n",
    "  locs = json.load(f)\n",
    "\n",
    "print('Entry count:', len(locs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c378352d",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "This code makes use of the sample `download` function from the slides. The JSON file is downloaded to `tournage.json`, which is then re-opened to analyze. Since there is an array at the root, `len` is simply called on the loaded JSON to get the entry count."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa1eca6",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d23f6",
   "metadata": {},
   "source": [
    "- Analyze the JSON file: what is its structure?\n",
    "- Write a function that converts an entry in a string that shows director, title, district, start date, end date, and geographic coordinates.\n",
    "- Convert all entries in strings (warning: some entries may have issues).\n",
    "- Display the first 20 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f051f79",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f48e3fd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.576923Z",
     "start_time": "2024-10-11T07:03:35.572252Z"
    },
    "slideshow": {
     "slide_type": ""
    }
   },
   "outputs": [],
   "source": [
    "def display_loc(entry):\n",
    "    fields = entry['fields']\n",
    "    director = fields.get('nom_realisateur', '<director missing>')\n",
    "    title = fields.get('nom_tournage', '<title missing>')\n",
    "    district = fields.get('ardt_lieu', '<district missing>')\n",
    "    start_date = fields.get('date_debut', '<start date missing>')\n",
    "    end_date = fields.get('date_fin', '<end date missing>')\n",
    "    coord_x = fields.get('coord_x', '<x coordinate missing>')\n",
    "    coord_y = fields.get('coord_y', '<y coordinate missing>')\n",
    "\n",
    "    return f\"{director}'s \\\"{title},\\\" filmed in {district} ({coord_x}, {coord_y}) from {start_date} to {end_date}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cb5f54",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "Metadata for each entry is stored in the `'fields'` key, however there may be missing fields for each entry. To safeguard for this, `dict.get` is used to give a default value in the case of a missing key.\n",
    "\n",
    "### File structure\n",
    "\n",
    "The JSON structure is an array of entries. The following is a formatted entry, to give an example of real data:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"datasetid\":\"lieux-de-tournage-a-paris\",\n",
    "   \"recordid\":\"0ff321c5b140a12a8e50a1b212a7c5f5bced91d7\",\n",
    "   \"fields\":{\n",
    "      \"coord_x\":2.37006242,\n",
    "      \"id_lieu\":\"2017-751\",\n",
    "      \"adresse_lieu\":\"rue du faubourg du temple, 75011 paris\",\n",
    "      \"geo_shape\":{\n",
    "         \"coordinates\":[\n",
    "            2.370062415669748,\n",
    "            48.8696979988026\n",
    "         ],\n",
    "         \"type\":\"Point\"\n",
    "      },\n",
    "      \"coord_y\":48.869698,\n",
    "      \"ardt_lieu\":\"75011\",\n",
    "      \"nom_tournage\":\"2 Fils (Nouvelle Demande Décor Librairie / Journées interverties)\",\n",
    "      \"nom_realisateur\":\"Félix MOATI\",\n",
    "      \"date_debut\":\"2017-10-19\",\n",
    "      \"type_tournage\":\"Long métrage\",\n",
    "      \"annee_tournage\":\"2017\",\n",
    "      \"nom_producteur\":\"NORD OUEST FILMS\",\n",
    "      \"date_fin\":\"2017-10-19\",\n",
    "      \"geo_point_2d\":[\n",
    "         48.8696979988026,\n",
    "         2.370062415669748\n",
    "      ]\n",
    "   },\n",
    "   \"geometry\":{\n",
    "      \"type\":\"Point\",\n",
    "      \"coordinates\":[\n",
    "         2.370062415669748,\n",
    "         48.8696979988026\n",
    "      ]\n",
    "   },\n",
    "   \"record_timestamp\":\"2024-01-31T13:40:46.402+01:00\"\n",
    "}\n",
    "```\n",
    "\n",
    "Each entry may be missing specific keys from `\"fields\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f86ee18d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.670903Z",
     "start_time": "2024-10-11T07:03:35.614408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Félix MOATI's \"2 Fils (Nouvelle Demande Décor Librairie / Journées interverties),\" filmed in 75011 (2.37006242, 48.869698) from 2017-10-19 to 2017-10-19\n",
      "Cathy Verney's \"Vernon Subutex,\" filmed in 75001 (2.34248745, 48.85849331) from 2018-04-25 to 2018-04-26\n",
      "Olivier Barma's \"LEBOWITZ CONTRE LEBOWITZ 2,\" filmed in 75010 (2.36463505, 48.87597364) from 2017-06-01 to 2017-06-01\n",
      "cheyenne carron's \"À jamais fidèle,\" filmed in 75020 (2.39860034, 48.85154734) from 2017-08-24 to 2017-08-25\n",
      "ZABOU BREITMAN's \"CHRONIQUES PARISIENNES 16,\" filmed in 75013 (2.38127943, 48.82655665) from 2017-04-18 to 2017-04-18\n",
      "Matthieu MARES-SAVELLI's \"LOLYWOOD - DANS TES REVES LE SPORT,\" filmed in 75019 (2.39778751, 48.89300518) from 2017-04-13 to 2017-04-13\n",
      "Hervé Mimran's \"Un homme pressé,\" filmed in 75012 (2.36913602, 48.84258571) from 2017-05-23 to 2017-05-24\n",
      "Cédric ANGER's \"L'AMOUR EST UNE FÊTE,\" filmed in 75018 (2.33709787, 48.88267038) from 2017-06-14 to 2017-06-14\n",
      "<director missing>'s \"LEBOWITZ CONTRE LEBOWITZ 2,\" filmed in 75010 (2.36442236, 48.8765691) from 2017-05-31 to 2017-05-31\n",
      "Renaud Bertrand - Noémie Saglio's \"Can't Buy me love,\" filmed in 75009 (2.34608771, 48.88227218) from 2018-05-15 to 2018-05-15\n",
      "Hector CABELL REYES's \"LE GENDRE IDEAL,\" filmed in 75010 (2.35378396, 48.87160116) from 2018-05-21 to 2018-05-21\n",
      "Léa Frédeval's \"Les Affamés,\" filmed in 75008 (2.32648299, 48.87278422) from 2017-07-16 to 2017-07-16\n",
      "VIANNEY LEBASQUE's \"LES BEAUX ESPRITS,\" filmed in 75010 (2.36564419, 48.87673941) from 2017-07-21 to 2017-07-22\n",
      "mabrouk el Mechri's \"nOX,\" filmed in 75020 (2.39242343, 48.87411444) from 2017-07-18 to 2017-07-18\n",
      "ARCHIE BORDERS's \"UNDER THE EIFFEL TOWER,\" filmed in 75008 (2.3022059, 48.86440696) from 2017-07-18 to 2017-07-18\n",
      "Franck Gastambide's \"Taxi 5,\" filmed in 75001 (2.33165128, 48.86314441) from 2017-07-28 to 2017-07-28\n",
      "ZABOU BREITMAN's \"CHRONIQUES PARISIENNES,\" filmed in 75010 (2.35302854, 48.87399125) from 2017-04-07 to 2017-04-07\n",
      "Cécilia Rouaud's \"BIG BANG,\" filmed in 75001 (2.34326304, 48.85510453) from 2017-03-29 to 2017-03-29\n",
      "NICOLAS SAADA's \"THANKSGIVING,\" filmed in 75007 (2.3281098, 48.85778012) from 2017-11-21 to 2017-11-21\n",
      "<director missing>'s \"CURIOSA,\" filmed in 75116 (2.29750439, 48.86576069) from 2017-11-30 to 2017-11-30\n"
     ]
    }
   ],
   "source": [
    "all_entries = [display_loc(e) for e in locs]\n",
    "print('\\n'.join(all_entries[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31bb085",
   "metadata": {},
   "source": [
    "- A same movie can have multiple shooting locations. Make a list of movies, where each entry contains the movie title, its director, and shootings locations (district, start date, end date).\n",
    "- How many movies do you have?\n",
    "- Write a function that converts a movie into a string that shows director, title, and shootings.\n",
    "- Convert all movies in strings.\n",
    "- Display the first 20 entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023a234",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f65854ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.675898Z",
     "start_time": "2024-10-11T07:03:35.672816Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Dict, TypeVar, List\n",
    "\n",
    "Movie = TypeVar('Movie')\n",
    "movies: Dict[str, Movie] = dict()\n",
    "\n",
    "for loc in locs:\n",
    "  title = loc['fields']['nom_tournage']\n",
    "  if title not in movies:\n",
    "    movies[title] = {\n",
    "      'title': title,\n",
    "      'director': loc['fields'].get('nom_realisateur', '<director missing>'),\n",
    "      'shootings': []\n",
    "    }\n",
    "  movies[title]['shootings'].append({\n",
    "    'district': loc['fields'].get('ardt_lieu', '<arrondissement missing>'),\n",
    "    'start_date': loc['fields']['date_debut'],\n",
    "    'end_date': loc['fields']['date_fin']\n",
    "  })\n",
    "\n",
    "# Regroup locations per movie\n",
    "movies: List[Movie] = [m for m in movies.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75d017c",
   "metadata": {},
   "source": [
    "### Explanation\n",
    "\n",
    "The question asks for two tasks to be accomplished:\n",
    "1. Entries are grouped by which movie they are a part of\n",
    "2. A subset of fields is displayed from each movie, including the newly aggregated field of shooting locations\n",
    "\n",
    "The most straightforward way to create this aggregation is via a dictionary. The movie title is chosen as the key, as there are no better unique identifier fields referencing the movie itself. \n",
    "\n",
    "While this organization is being done, the opportunity is taken to normalize the data into a new structure containing exactly what we need, and with no fields missing:\n",
    "\n",
    "```json\n",
    "A Movie is a dictionary with the schema:\n",
    "\n",
    "{\n",
    "  \"title\": \"string\",\n",
    "  \"director\": \"string\",\n",
    "  \"shootings\": [\n",
    "    {\n",
    "      \"district\": \"string\",\n",
    "      \"start_date\": \"string\",\n",
    "      \"end_date\": \"string\"\n",
    "    },\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Since the top-level dictionary was only needed for the process of organization, and not for the final data representation, we re-organize all of its values into a list for the final `movies` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5cb17c8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.728960Z",
     "start_time": "2024-10-11T07:03:35.721811Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1476"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c07db010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.740289Z",
     "start_time": "2024-10-11T07:03:35.730968Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def display_movie(movie):\n",
    "    movie_str = f\"{movie['director']}'s \\\"{movie['title']},\\\" was filmed in the following locations:\\n\"\n",
    "    for shooting in movie['shootings']:\n",
    "        movie_str += f'- {shooting['district']} between {shooting['start_date']} and {shooting['end_date']}\\n'\n",
    "    return movie_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b5e8374d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.773580Z",
     "start_time": "2024-10-11T07:03:35.753086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Félix MOATI's \"2 Fils (Nouvelle Demande Décor Librairie / Journées interverties),\" was filmed in the following locations:\n",
      "- 75011 between 2017-10-19 and 2017-10-19\n",
      "- 75011 between 2017-10-19 and 2017-10-19\n",
      "\n",
      "Cathy Verney's \"Vernon Subutex,\" was filmed in the following locations:\n",
      "- 75001 between 2018-04-25 and 2018-04-26\n",
      "- 75019 between 2018-05-22 and 2018-05-22\n",
      "- 75019 between 2018-05-25 and 2018-05-25\n",
      "- 75010 between 2018-05-03 and 2018-05-06\n",
      "- 75011 between 2018-03-19 and 2018-03-19\n",
      "- 75011 between 2018-06-01 and 2018-06-02\n",
      "- 75014 between 2018-06-05 and 2018-06-14\n",
      "- 75014 between 2018-06-13 and 2018-06-13\n",
      "- 75019 between 2018-05-22 and 2018-05-22\n",
      "- 75009 between 2018-04-11 and 2018-04-11\n",
      "- 75007 between 2018-06-13 and 2018-06-15\n",
      "- 75012 between 2018-03-23 and 2018-03-23\n",
      "- 75011 between 2018-04-04 and 2018-04-04\n",
      "- 75016 between 2018-03-30 and 2018-03-30\n",
      "- 75004 between 2018-03-20 and 2018-03-20\n",
      "- 75004 between 2018-04-26 and 2018-04-27\n",
      "- 75012 between 2018-08-28 and 2018-08-30\n",
      "- 75011 between 2018-03-19 and 2018-03-19\n",
      "- 75002 between 2018-03-20 and 2018-03-20\n",
      "- 75009 between 2018-04-09 and 2018-04-10\n",
      "- 75010 between 2018-08-28 and 2018-08-30\n",
      "- 75012 between 2018-08-28 and 2018-08-30\n",
      "- 75020 between 2018-04-05 and 2018-04-05\n",
      "- 75019 between 2018-05-21 and 2018-05-22\n",
      "- 75011 between 2018-05-08 and 2018-05-12\n",
      "- 75012 between 2018-08-28 and 2018-08-30\n",
      "- 75019 between 2018-05-28 and 2018-05-29\n",
      "- 75019 between 2018-05-30 and 2018-05-31\n",
      "- 75001 between 2018-04-25 and 2018-04-26\n",
      "- 75010 between 2018-05-31 and 2018-05-31\n",
      "- 75014 between 2018-06-13 and 2018-06-13\n",
      "- 75012 between 2018-03-23 and 2018-03-23\n",
      "- 75001 between 2018-04-25 and 2018-04-26\n",
      "- 75019 between 2018-05-24 and 2018-05-24\n",
      "- 75019 between 2018-05-29 and 2018-05-31\n",
      "- 75010 between 2018-05-31 and 2018-05-31\n",
      "- 75019 between 2018-05-25 and 2018-05-25\n",
      "- 75019 between 2018-05-22 and 2018-05-23\n",
      "- 75006 between 2018-04-25 and 2018-04-26\n",
      "- 75001 between 2018-04-25 and 2018-04-26\n",
      "- 75019 between 2018-05-21 and 2018-05-21\n",
      "- 75012 between 2018-05-02 and 2018-05-02\n",
      "- 75002 between 2018-05-08 and 2018-05-08\n",
      "- 75116 between 2018-04-16 and 2018-04-16\n",
      "- 75019 between 2018-05-24 and 2018-05-25\n",
      "- 75009 between 2018-04-09 and 2018-04-12\n",
      "- 75019 between 2018-05-30 and 2018-05-31\n",
      "- 75016 between 2018-03-30 and 2018-03-30\n",
      "- 75019 between 2018-05-21 and 2018-05-22\n",
      "- 75019 between 2018-05-29 and 2018-05-31\n",
      "- 75006 between 2018-04-25 and 2018-04-25\n",
      "- 75019 between 2018-05-24 and 2018-05-24\n",
      "- 75017 between 2018-05-31 and 2018-07-31\n",
      "- 75011 between 2018-04-06 and 2018-04-06\n",
      "- 75014 between 2018-06-13 and 2018-06-13\n",
      "- 75008 between 2018-06-13 and 2018-06-14\n",
      "- 75001 between 2018-06-13 and 2018-06-15\n",
      "- 75009 between 2018-05-31 and 2018-06-02\n",
      "- 75116 between 2018-04-12 and 2018-04-18\n",
      "- 75116 between 2018-04-12 and 2018-04-12\n",
      "\n",
      "Olivier Barma's \"LEBOWITZ CONTRE LEBOWITZ 2,\" was filmed in the following locations:\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75010 between 2017-05-31 and 2017-05-31\n",
      "- 75010 between 2017-05-31 and 2017-05-31\n",
      "- 75116 between 2017-05-29 and 2017-05-29\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75010 between 2017-05-31 and 2017-05-31\n",
      "- 75116 between 2017-05-29 and 2017-05-30\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75010 between 2017-05-31 and 2017-05-31\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75016 between 2017-06-12 and 2017-06-12\n",
      "- 75010 between 2017-06-01 and 2017-06-01\n",
      "- 75116 between 2017-05-29 and 2017-05-29\n",
      "\n",
      "cheyenne carron's \"À jamais fidèle,\" was filmed in the following locations:\n",
      "- 75020 between 2017-08-24 and 2017-08-25\n",
      "- 75016 between 2017-08-22 and 2017-08-22\n",
      "- 75020 between 2017-08-23 and 2017-08-23\n",
      "- 75016 between 2017-08-11 and 2017-08-11\n",
      "- 75016 between 2017-08-03 and 2017-08-04\n",
      "- 75016 between 2017-08-08 and 2017-08-08\n",
      "- 75011 between 2017-08-21 and 2017-08-22\n",
      "- 75116 between 2017-08-11 and 2017-08-11\n",
      "- 75020 between 2017-08-25 and 2017-08-25\n",
      "- 75020 between 2017-08-23 and 2017-08-24\n",
      "- 75016 between 2017-08-09 and 2017-08-09\n",
      "- 75020 between 2017-08-25 and 2017-08-25\n",
      "- 75016 between 2017-07-31 and 2017-07-31\n",
      "- 75016 between 2017-08-22 and 2017-08-23\n",
      "- 75016 between 2017-08-11 and 2017-08-11\n",
      "- 75116 between 2017-08-11 and 2017-08-11\n",
      "- 75116 between 2017-08-11 and 2017-08-11\n",
      "- 75011 between 2017-08-21 and 2017-08-21\n",
      "- 75020 between 2017-08-25 and 2017-08-25\n",
      "- 75016 between 2017-08-03 and 2017-08-04\n",
      "- 75020 between 2017-08-04 and 2017-08-05\n",
      "- 75011 between 2017-08-21 and 2017-08-22\n",
      "- 75016 between 2017-08-03 and 2017-08-04\n",
      "- 75020 between 2017-08-25 and 2017-08-25\n",
      "- 75016 between 2017-07-31 and 2017-07-31\n",
      "- 75020 between 2017-08-22 and 2017-08-22\n",
      "- 75116 between 2017-08-11 and 2017-08-11\n",
      "- 75016 between 2017-08-08 and 2017-08-08\n",
      "- 75016 between 2017-08-09 and 2017-08-09\n",
      "- 75016 between 2017-07-31 and 2017-07-31\n",
      "\n",
      "ZABOU BREITMAN's \"CHRONIQUES PARISIENNES 16,\" was filmed in the following locations:\n",
      "- 75013 between 2017-04-18 and 2017-04-18\n",
      "- 75013 between 2017-04-18 and 2017-04-18\n",
      "- 75013 between 2017-04-18 and 2017-04-18\n",
      "- 75013 between 2017-04-18 and 2017-04-18\n",
      "- 75013 between 2017-04-18 and 2017-04-18\n",
      "\n",
      "Matthieu MARES-SAVELLI's \"LOLYWOOD - DANS TES REVES LE SPORT,\" was filmed in the following locations:\n",
      "- 75019 between 2017-04-13 and 2017-04-13\n",
      "\n",
      "Hervé Mimran's \"Un homme pressé,\" was filmed in the following locations:\n",
      "- 75012 between 2017-05-23 and 2017-05-24\n",
      "- 75116 between 2017-07-13 and 2017-07-14\n",
      "- 75116 between 2017-07-12 and 2017-07-12\n",
      "- 75116 between 2017-07-11 and 2017-07-12\n",
      "- 75015 between 2017-07-17 and 2017-07-17\n",
      "- 75004 between 2017-07-08 and 2017-07-09\n",
      "- 75005 between 2017-07-06 and 2017-07-07\n",
      "- 75007 between 2017-07-06 and 2017-07-06\n",
      "- 75116 between 2017-07-07 and 2017-07-07\n",
      "- 75007 between 2017-07-17 and 2017-07-17\n",
      "- 75017 between 2017-07-04 and 2017-07-05\n",
      "- 75013 between 2017-07-14 and 2017-07-14\n",
      "- 75013 between 2017-05-24 and 2017-05-25\n",
      "- 75016 between 2017-07-12 and 2017-07-12\n",
      "- 75013 between 2017-05-23 and 2017-05-24\n",
      "- 75005 between 2017-06-12 and 2017-06-12\n",
      "- 75116 between 2017-05-24 and 2017-05-24\n",
      "- 75012 between 2017-07-17 and 2017-07-18\n",
      "\n",
      "Cédric ANGER's \"L'AMOUR EST UNE FÊTE,\" was filmed in the following locations:\n",
      "- 75018 between 2017-06-14 and 2017-06-14\n",
      "- 75009 between 2017-06-14 and 2017-06-14\n",
      "- 75018 between 2017-06-13 and 2017-06-13\n",
      "- 75018 between 2017-06-13 and 2017-06-14\n",
      "- 75018 between 2017-06-12 and 2017-06-13\n",
      "- 75018 between 2017-06-14 and 2017-06-15\n",
      "\n",
      "Renaud Bertrand - Noémie Saglio's \"Can't Buy me love,\" was filmed in the following locations:\n",
      "- 75009 between 2018-05-15 and 2018-05-15\n",
      "- 75009 between 2018-04-10 and 2018-04-11\n",
      "- 75004 between 2018-04-02 and 2018-04-02\n",
      "- 75009 between 2018-04-04 and 2018-04-05\n",
      "- 75009 between 2018-05-11 and 2018-05-11\n",
      "- 75018 between 2018-05-15 and 2018-05-16\n",
      "- 75004 between 2018-05-17 and 2018-05-17\n",
      "- 75004 between 2018-05-17 and 2018-05-17\n",
      "- 75011 between 2018-03-26 and 2018-03-26\n",
      "- 75011 between 2018-05-08 and 2018-05-09\n",
      "- 75019 between 2018-05-04 and 2018-05-04\n",
      "- 75009 between 2018-04-04 and 2018-04-05\n",
      "- 75002 between 2018-05-14 and 2018-05-15\n",
      "- 75009 between 2018-04-11 and 2018-04-11\n",
      "- 75009 between 2018-04-25 and 2018-04-26\n",
      "- 75009 between 2018-05-15 and 2018-05-16\n",
      "- 75004 between 2018-04-02 and 2018-04-02\n",
      "- 75009 between 2018-04-28 and 2018-04-28\n",
      "- 75009 between 2018-05-02 and 2018-05-02\n",
      "- 75116 between 2018-03-19 and 2018-03-19\n",
      "- 75011 between 2018-03-26 and 2018-03-26\n",
      "- 75116 between 2018-05-09 and 2018-05-11\n",
      "- 75009 between 2018-05-15 and 2018-05-15\n",
      "- 75019 between 2018-03-28 and 2018-03-28\n",
      "- 75009 between 2018-03-30 and 2018-03-30\n",
      "- 75019 between 2018-03-28 and 2018-03-28\n",
      "- 75004 between 2018-05-17 and 2018-05-17\n",
      "- 75001 between 2018-05-18 and 2018-05-19\n",
      "- 75019 between 2018-03-15 and 2018-03-15\n",
      "- 75019 between 2018-03-15 and 2018-03-15\n",
      "- 75004 between 2018-04-02 and 2018-04-02\n",
      "- 75009 between 2018-04-27 and 2018-04-27\n",
      "- 75019 between 2018-03-15 and 2018-03-15\n",
      "- 75009 between 2018-04-23 and 2018-04-23\n",
      "- 75019 between 2018-05-03 and 2018-05-05\n",
      "- 75009 between 2018-05-16 and 2018-05-16\n",
      "- 75004 between 2018-05-17 and 2018-05-18\n",
      "- 75009 between 2018-04-12 and 2018-04-12\n",
      "- 75019 between 2018-03-30 and 2018-03-30\n",
      "- 75003 between 2018-03-20 and 2018-03-21\n",
      "- 75009 between 2018-04-03 and 2018-04-04\n",
      "- 75009 between 2018-04-04 and 2018-04-04\n",
      "- 75009 between 2018-04-20 and 2018-04-21\n",
      "- 75002 between 2018-05-14 and 2018-05-14\n",
      "- 75019 between 2018-03-15 and 2018-03-15\n",
      "- 75009 between 2018-04-04 and 2018-04-04\n",
      "- 75019 between 2018-03-30 and 2018-03-30\n",
      "- 75009 between 2018-04-03 and 2018-04-05\n",
      "- 75009 between 2018-04-27 and 2018-04-27\n",
      "- 75009 between 2018-04-25 and 2018-04-29\n",
      "- 75009 between 2018-04-11 and 2018-04-12\n",
      "- 75019 between 2018-03-28 and 2018-03-30\n",
      "- 75008 between 2018-05-11 and 2018-05-11\n",
      "- 75009 between 2018-05-16 and 2018-05-16\n",
      "- 75004 between 2018-05-17 and 2018-05-17\n",
      "- 75020 between 2018-03-16 and 2018-03-17\n",
      "\n",
      "Hector CABELL REYES's \"LE GENDRE IDEAL,\" was filmed in the following locations:\n",
      "- 75010 between 2018-05-21 and 2018-05-21\n",
      "- 75001 between 2018-07-18 and 2018-07-20\n",
      "- 75010 between 2018-05-21 and 2018-05-21\n",
      "- 75019 between 2018-05-31 and 2018-06-01\n",
      "\n",
      "Léa Frédeval's \"Les Affamés,\" was filmed in the following locations:\n",
      "- 75008 between 2017-07-16 and 2017-07-16\n",
      "- 75009 between 2017-06-28 and 2017-06-28\n",
      "- 75012 between 2017-06-09 and 2017-06-09\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75018 between 2017-06-08 and 2017-06-08\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75007 between 2017-06-20 and 2017-06-21\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75010 between 2017-07-13 and 2017-07-13\n",
      "- 75012 between 2017-06-09 and 2017-06-09\n",
      "- 75012 between 2017-06-09 and 2017-06-09\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75007 between 2017-05-19 and 2017-05-20\n",
      "- 75012 between 2017-06-06 and 2017-06-06\n",
      "- 75018 between 2017-06-26 and 2017-06-26\n",
      "- 75004 between 2017-06-30 and 2017-06-30\n",
      "- 75012 between 2017-06-09 and 2017-06-09\n",
      "\n",
      "VIANNEY LEBASQUE's \"LES BEAUX ESPRITS,\" was filmed in the following locations:\n",
      "- 75010 between 2017-07-21 and 2017-07-22\n",
      "- 75010 between 2017-07-21 and 2017-07-21\n",
      "- 75010 between 2017-08-31 and 2017-08-31\n",
      "- 75010 between 2017-08-29 and 2017-08-29\n",
      "- 75010 between 2017-07-24 and 2017-07-25\n",
      "- 75014 between 2017-08-17 and 2017-08-18\n",
      "- 75014 between 2017-08-18 and 2017-08-19\n",
      "- 75013 between 2017-08-03 and 2017-08-03\n",
      "- 75010 between 2017-07-24 and 2017-07-24\n",
      "- 75015 between 2017-08-25 and 2017-08-26\n",
      "- 75019 between 2017-07-27 and 2017-07-27\n",
      "- 75010 between 2017-08-30 and 2017-08-30\n",
      "\n",
      "mabrouk el Mechri's \"nOX,\" was filmed in the following locations:\n",
      "- 75020 between 2017-07-18 and 2017-07-18\n",
      "\n",
      "ARCHIE BORDERS's \"UNDER THE EIFFEL TOWER,\" was filmed in the following locations:\n",
      "- 75008 between 2017-07-18 and 2017-07-18\n",
      "- 75007 between 2017-07-19 and 2017-07-19\n",
      "- 75014 between 2017-07-18 and 2017-07-18\n",
      "\n",
      "Franck Gastambide's \"Taxi 5,\" was filmed in the following locations:\n",
      "- 75001 between 2017-07-28 and 2017-07-28\n",
      "- 75116 between 2017-07-26 and 2017-07-26\n",
      "- 75116 between 2017-07-25 and 2017-07-25\n",
      "- 75003 between 2017-07-25 and 2017-07-25\n",
      "- 75116 between 2017-07-27 and 2017-07-27\n",
      "- 75116 between 2017-07-27 and 2017-07-27\n",
      "- 75116 between 2017-07-27 and 2017-07-27\n",
      "\n",
      "ZABOU BREITMAN's \"CHRONIQUES PARISIENNES,\" was filmed in the following locations:\n",
      "- 75010 between 2017-04-07 and 2017-04-07\n",
      "- 75013 between 2017-02-15 and 2017-02-15\n",
      "- 75013 between 2017-02-15 and 2017-02-15\n",
      "- 75007 between 2016-10-01 and 2016-10-01\n",
      "- 75004 between 2017-05-19 and 2017-05-19\n",
      "- 75013 between 2017-02-13 and 2017-02-13\n",
      "- 75013 between 2017-02-15 and 2017-02-15\n",
      "- 75004 between 2016-10-01 and 2016-10-01\n",
      "- 75006 between 2017-03-09 and 2017-03-09\n",
      "- 75004 between 2017-04-13 and 2017-04-13\n",
      "- 75019 between 2017-03-21 and 2017-03-21\n",
      "- 75013 between 2017-02-15 and 2017-02-15\n",
      "- 75008 between 2016-12-29 and 2016-12-29\n",
      "- 75014 between 2017-03-28 and 2017-03-28\n",
      "- 75004 between 2017-03-29 and 2017-03-29\n",
      "- 75013 between 2017-02-15 and 2017-02-15\n",
      "- 75009 between 2016-12-29 and 2016-12-29\n",
      "- 75009 between 2016-12-29 and 2016-12-29\n",
      "- 75010 between 2017-04-10 and 2017-04-10\n",
      "- 75014 between 2017-04-04 and 2017-04-04\n",
      "- 75010 between 2017-03-10 and 2017-03-10\n",
      "- 75001 between 2017-02-22 and 2017-02-22\n",
      "- 75001 between 2016-10-01 and 2016-10-01\n",
      "- 75004 between 2016-10-01 and 2016-10-01\n",
      "- 75015 between 2016-10-01 and 2016-10-01\n",
      "- 75007 between 2016-10-01 and 2016-10-01\n",
      "- 75013 between 2017-03-03 and 2017-03-03\n",
      "- 75004 between 2017-05-23 and 2017-05-24\n",
      "- 75010 between 2017-03-21 and 2017-03-21\n",
      "- 75004 between 2017-03-30 and 2017-03-30\n",
      "- 75004 between 2017-04-13 and 2017-04-13\n",
      "- 75007 between 2016-12-29 and 2016-12-29\n",
      "- 75007 between 2017-03-10 and 2017-03-11\n",
      "- 75013 between 2017-02-14 and 2017-02-14\n",
      "- 75001 between 2017-03-14 and 2017-03-14\n",
      "- 75007 between 2017-04-19 and 2017-04-20\n",
      "- 75001 between 2016-10-01 and 2016-10-01\n",
      "- 75004 between 2016-10-01 and 2016-10-01\n",
      "- 75008 between 2016-12-29 and 2016-12-29\n",
      "- 75004 between 2016-10-01 and 2016-10-01\n",
      "- 75001 between 2016-12-29 and 2016-12-29\n",
      "- 75001 between 2016-10-01 and 2016-10-01\n",
      "- 75001 between 2016-10-01 and 2016-10-01\n",
      "- 75002 between 2017-04-12 and 2017-04-12\n",
      "- 75003 between 2017-03-10 and 2017-03-10\n",
      "- 75002 between 2017-03-14 and 2017-03-14\n",
      "- 75007 between 2016-10-01 and 2016-10-01\n",
      "- 75006 between 2017-05-18 and 2017-05-18\n",
      "- 75008 between 2016-12-29 and 2016-12-29\n",
      "- 75013 between 2017-03-03 and 2017-03-03\n",
      "- 75016 between 2016-10-01 and 2016-10-01\n",
      "- 75007 between 2016-10-01 and 2016-10-01\n",
      "- 75010 between 2017-04-05 and 2017-04-10\n",
      "- 75001 between 2016-10-01 and 2016-10-01\n",
      "\n",
      "Cécilia Rouaud's \"BIG BANG,\" was filmed in the following locations:\n",
      "- 75001 between 2017-03-29 and 2017-03-29\n",
      "- 75019 between 2017-03-22 and 2017-03-22\n",
      "- 75009 between 2017-03-17 and 2017-03-17\n",
      "- 75016 between 2017-03-27 and 2017-03-28\n",
      "- 75006 between 2017-03-29 and 2017-03-29\n",
      "- 75010 between 2017-02-22 and 2017-02-22\n",
      "- 75009 between 2017-03-17 and 2017-03-17\n",
      "- 75009 between 2017-04-10 and 2017-04-11\n",
      "- 75014 between 2017-03-24 and 2017-03-24\n",
      "- 75013 between 2017-03-01 and 2017-03-01\n",
      "- 75001 between 2017-03-28 and 2017-03-28\n",
      "- 75006 between 2017-03-24 and 2017-03-24\n",
      "- 75013 between 2017-03-02 and 2017-03-02\n",
      "\n",
      "NICOLAS SAADA's \"THANKSGIVING,\" was filmed in the following locations:\n",
      "- 75007 between 2017-11-21 and 2017-11-21\n",
      "- 75010 between 2017-11-06 and 2017-11-06\n",
      "- 75007 between 2017-11-21 and 2017-11-21\n",
      "- 75008 between 2017-11-17 and 2017-11-17\n",
      "- 75008 between 2017-11-21 and 2017-11-21\n",
      "- 75012 between 2017-11-15 and 2017-11-15\n",
      "- 75006 between 2017-11-07 and 2017-11-07\n",
      "- 75007 between 2017-11-07 and 2017-11-07\n",
      "- 75116 between 2017-11-23 and 2017-11-23\n",
      "- 75008 between 2017-11-21 and 2017-11-21\n",
      "- 75008 between 2017-11-20 and 2017-11-20\n",
      "\n",
      "<director missing>'s \"CURIOSA,\" was filmed in the following locations:\n",
      "- 75116 between 2017-11-30 and 2017-11-30\n",
      "- 75004 between 2017-10-24 and 2017-10-24\n",
      "- 75009 between 2017-11-13 and 2017-11-13\n",
      "- 75116 between 2017-11-30 and 2017-11-30\n",
      "- 75116 between 2017-11-30 and 2017-11-30\n",
      "\n",
      "David Hourrègue's \"Skam,\" was filmed in the following locations:\n",
      "- 75008 between 2017-11-29 and 2017-11-29\n",
      "- 75004 between 2017-12-06 and 2017-12-06\n",
      "- 75018 between 2017-11-23 and 2017-11-23\n",
      "- 75012 between 2017-11-10 and 2017-11-10\n",
      "- 75008 between 2017-11-30 and 2017-11-30\n",
      "- 75004 between 2017-12-06 and 2017-12-07\n",
      "- 75011 between 2017-11-13 and 2017-11-13\n",
      "- 75012 between 2017-11-10 and 2017-11-10\n",
      "- 75019 between 2017-12-04 and 2017-12-04\n",
      "- 75011 between 2017-10-24 and 2017-10-24\n",
      "- 75019 between 2017-12-04 and 2017-12-04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_movie_displays = [display_movie(m) for m in movies]\n",
    "print('\\n'.join(all_movie_displays[:20]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6188458f",
   "metadata": {},
   "source": [
    "- Display for each district its number of shootings. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25c863",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bbf057c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.806608Z",
     "start_time": "2024-10-11T07:03:35.793705Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'75018': 1043,\n",
       " '75008': 798,\n",
       " '75010': 749,\n",
       " '75019': 745,\n",
       " '75001': 722,\n",
       " '75004': 670,\n",
       " '75013': 658,\n",
       " '75007': 657,\n",
       " '75009': 642,\n",
       " '75011': 641,\n",
       " '75005': 640,\n",
       " '75016': 614,\n",
       " '75012': 596,\n",
       " '75020': 587,\n",
       " '75006': 471,\n",
       " '75116': 421,\n",
       " '75017': 378,\n",
       " '75015': 363,\n",
       " '75014': 321,\n",
       " '75002': 297,\n",
       " '75003': 236,\n",
       " '93500': 6,\n",
       " '94320': 4,\n",
       " '???': 1,\n",
       " '93320': 1,\n",
       " '92220': 1,\n",
       " '92170': 1,\n",
       " '93200': 1,\n",
       " '93000': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Dict\n",
    "\n",
    "def district_count_reducer(acc: Dict[str, int], )\n",
    "\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b58306",
   "metadata": {},
   "source": [
    "# Exercice 4 - Analyze CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2fe268",
   "metadata": {},
   "source": [
    "- Write a Python code retrieves the file of the most loaned titles in libraries in Paris at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "663845ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:35.818501Z",
     "start_time": "2024-10-11T07:03:35.808870Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://opendata.paris.fr/explore/dataset/les-titres-les-plus-pretes/download/?format=csv&timezone=Europe/Berlin&lang=en&use_labels_for_header=true&csv_separator=%3B\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3296ee1",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d665083",
   "metadata": {},
   "source": [
    "- Analyze the resulting CSV file to display, for all entries: title, author, and total number of loans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c39b1",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22877be1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.078350Z",
     "start_time": "2024-10-11T07:03:36.075015Z"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def disp_book(book):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1b29eaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.115744Z",
     "start_time": "2024-10-11T07:03:36.103623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Razzia\", by Sobral,  Patrick (2938 loans)\n",
      "\"Touche pas à mon veau\", by Guibert,  Emmanuel (2296 loans)\n",
      "\"Max et Lili vont chez papy et mamie\", by Saint-Mars,  Dominique de (5554 loans)\n",
      "\"Lili veut un petit chat\", by Saint-Mars,  Dominique de (5789 loans)\n",
      "\"Max et Lili font du camping\", by Saint-Mars,  Dominique de (5658 loans)\n",
      "\"Lili trouve sa maîtresse méchante\", by Saint-Mars,  Dominique de (4694 loans)\n",
      "\"J'irai où tu iras\", by Lyfoung,  Patricia (4707 loans)\n",
      "\"Les nerfs à vif\", by Nob (2837 loans)\n",
      "\"Je crois que je t'aime\", by Lyfoung,  Patricia (3878 loans)\n",
      "\"Attention tornade\", by Cazenove,  Christophe (2366 loans)\n",
      "\"Max et Lili se posent des questions sur Dieu\", by Saint-Mars,  Dominique de (4823 loans)\n",
      "\"Game over. 13. Toxic affair\", by Midam (2652 loans)\n",
      "\"Les Schtroumpfs et la tempête blanche\", by Jost,  Alain (975 loans)\n",
      "\"On a marché sur la lune\", by Hergé (5674 loans)\n",
      "\"Astérix chez les Bretons\", by Goscinny,  René (3014 loans)\n",
      "\"Parvati\", by Ogaki,  Philippe (2616 loans)\n",
      "\"Les Schtroumpfs et l'arbre d'or\", by Culliford,  Thierry (3460 loans)\n",
      "\"La décision : roman\", by Tuil,  Karine (976 loans)\n",
      "\"Les cahiers d'Esther. 4. Histoires de mes 13 ans\", by Sattouf,  Riad (2171 loans)\n",
      "\"Salut, les zinzins !\", by Cohen,  Jacqueline (4565 loans)\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join( [disp_book(b) for b in books[:20]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1043a24",
   "metadata": {},
   "source": [
    "- Display for each type of document (there can be several entries for the same type of document), the total number of loans for this type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6077c6",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48b92fb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.142096Z",
     "start_time": "2024-10-11T07:03:36.130485Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bande dessinée jeunesse': 2300143,\n",
       " 'Livre jeunesse': 104067,\n",
       " 'Bande dessinée adulte': 59726,\n",
       " 'Livre adulte': 41731,\n",
       " 'Bande dessinée ado': 29819,\n",
       " 'Livre sonore jeunesse': 10630,\n",
       " 'Jeux de société prêtable': 10057,\n",
       " 'Musique jeunesse': 4792,\n",
       " 'Jeux vidéos tous publics Non prêtables': 4235,\n",
       " 'DVD jeunesse': 2471,\n",
       " 'Jeux de société': 1753}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2853229",
   "metadata": {},
   "source": [
    "- Display titles in order of profitability (in descending order of the number of loans per copy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "26d95669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.167624Z",
     "start_time": "2024-10-11T07:03:36.158896Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Console Nintendo Switch\" (1648 loans, 2 copies)\n",
      "\"Console PlayStation 4\" (2587 loans, 6 copies)\n",
      "\"SOS ouistiti :\" (1868 loans, 5 copies)\n",
      "\"Quatre en ligne :\" (1753 loans, 5 copies)\n",
      "\"Perplexus : : original\" (2254 loans, 8 copies)\n",
      "\"Un enfant chez les schtroumpfs\", by Díaz Vizoso,  Miguel (4504 loans, 43 copies)\n",
      "\"Mon meilleur ami\", by Verron,  Laurent (4662 loans, 47 copies)\n",
      "\"Les vacances infernales\", by Cohen,  Jacqueline (5014 loans, 51 copies)\n",
      "\"Bande de sauvages !\", by Cohen,  Jacqueline (5761 loans, 60 copies)\n",
      "\"Trop, c'est trop !\", by Cohen,  Jacqueline (4504 loans, 47 copies)\n",
      "\"Les fous du mercredi\", by Cohen,  Jacqueline (5169 loans, 54 copies)\n",
      "\"Ca va chauffer !\", by Cohen,  Jacqueline (4071 loans, 44 copies)\n",
      "\"Uno :\" (3136 loans, 34 copies)\n",
      "\"Ca roule !\", by Cohen,  Jacqueline (5763 loans, 63 copies)\n",
      "\"Salut, les zinzins !\", by Cohen,  Jacqueline (4565 loans, 50 copies)\n",
      "\"Les deux terreurs\", by Cohen,  Jacqueline (3999 loans, 44 copies)\n",
      "\"Subliiiimes !\", by Cohen,  Jacqueline (5007 loans, 56 copies)\n",
      "\"Un copieur sachant copier\", by Godi,  Bernard (3481 loans, 39 copies)\n",
      "\"A l'attaque !\", by Cohen,  Jacqueline (4353 loans, 49 copies)\n",
      "\"Tom-Tom et l'impossible Nana\", by Cohen,  Jacqueline (5832 loans, 66 copies)\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join( [disp_book(b) for b in sorted_books[:20]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf5668b",
   "metadata": {},
   "source": [
    "# Exercice 5 * - Analyze HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85237162",
   "metadata": {},
   "source": [
    "- Write a Python program that gets the content of the Wikipedia page at: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "57dc6b89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.180211Z",
     "start_time": "2024-10-11T07:03:36.168632Z"
    }
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/List_of_countries_and_dependencies_by_population_density\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7e866",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f271cbfd",
   "metadata": {},
   "source": [
    "- Display all the countries mentioned in the table. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ff5df",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff7ad3f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:36.660044Z",
     "start_time": "2024-10-11T07:03:36.649884Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Monaco',\n",
       " 'Singapore',\n",
       " 'Bahrain',\n",
       " 'Maldives',\n",
       " 'Malta',\n",
       " 'Vatican City',\n",
       " 'Bangladesh',\n",
       " 'Taiwan',\n",
       " 'Mauritius',\n",
       " 'Barbados',\n",
       " 'Nauru',\n",
       " 'San Marino',\n",
       " 'Rwanda',\n",
       " 'South Korea',\n",
       " 'Lebanon',\n",
       " 'Burundi',\n",
       " 'Tuvalu',\n",
       " 'India',\n",
       " 'Netherlands',\n",
       " 'Haiti',\n",
       " 'Israel',\n",
       " 'Philippines',\n",
       " 'Belgium',\n",
       " 'Comoros',\n",
       " 'Grenada',\n",
       " 'Sri Lanka',\n",
       " 'Japan',\n",
       " 'El Salvador',\n",
       " 'Pakistan',\n",
       " 'Trinidad and Tobago',\n",
       " 'Vietnam',\n",
       " 'Saint Lucia',\n",
       " 'United Kingdom',\n",
       " 'Saint Vincent and the Grenadines',\n",
       " 'Jamaica',\n",
       " 'Luxembourg',\n",
       " 'Liechtenstein',\n",
       " 'Gambia',\n",
       " 'Nigeria',\n",
       " 'Kuwait',\n",
       " 'São Tomé and Príncipe',\n",
       " 'Seychelles',\n",
       " 'Qatar',\n",
       " 'Germany',\n",
       " 'Dominican Republic',\n",
       " 'Marshall Islands',\n",
       " 'Malawi',\n",
       " 'North Korea',\n",
       " 'Antigua and Barbuda',\n",
       " 'Switzerland',\n",
       " 'Nepal',\n",
       " 'Uganda',\n",
       " 'Italy',\n",
       " 'Kiribati',\n",
       " 'Saint Kitts and Nevis',\n",
       " 'Andorra',\n",
       " 'Guatemala',\n",
       " 'Micronesia',\n",
       " 'Togo',\n",
       " 'Kosovo',\n",
       " 'China',\n",
       " 'Cape Verde',\n",
       " 'Isle of Man',\n",
       " 'Indonesia',\n",
       " 'Tonga',\n",
       " 'Ghana',\n",
       " 'Thailand',\n",
       " 'Denmark',\n",
       " 'Cyprus',\n",
       " 'United Arab Emirates',\n",
       " 'Transnistria',\n",
       " 'Czech Republic',\n",
       " 'Jordan',\n",
       " 'Syria',\n",
       " 'Sierra Leone',\n",
       " 'Poland',\n",
       " 'Azerbaijan',\n",
       " 'Benin',\n",
       " 'Slovakia',\n",
       " 'Ethiopia',\n",
       " 'Northern Cyprus',\n",
       " 'Egypt',\n",
       " 'Portugal',\n",
       " 'Turkey',\n",
       " 'Hungary',\n",
       " 'Austria',\n",
       " 'Iraq',\n",
       " 'Slovenia',\n",
       " 'Malaysia',\n",
       " 'Costa Rica',\n",
       " 'Cuba',\n",
       " 'Moldova',\n",
       " 'Albania',\n",
       " 'Dominica',\n",
       " 'Spain',\n",
       " 'Honduras',\n",
       " 'Cambodia',\n",
       " 'Armenia',\n",
       " 'Kenya',\n",
       " 'East Timor',\n",
       " 'Senegal',\n",
       " 'Ivory Coast',\n",
       " 'Burkina Faso',\n",
       " 'Romania',\n",
       " 'North Macedonia',\n",
       " 'Serbia',\n",
       " 'Myanmar',\n",
       " 'Samoa',\n",
       " 'Brunei',\n",
       " 'Greece',\n",
       " 'Uzbekistan',\n",
       " 'Lesotho',\n",
       " 'Tunisia',\n",
       " 'Ireland',\n",
       " 'Cook Islands',\n",
       " 'Tajikistan',\n",
       " 'Tanzania',\n",
       " 'Croatia',\n",
       " 'Ecuador',\n",
       " 'Eswatini',\n",
       " 'Mexico',\n",
       " 'Yemen',\n",
       " 'Afghanistan',\n",
       " 'Bosnia and Herzegovina',\n",
       " 'Equatorial Guinea',\n",
       " 'Ukraine',\n",
       " 'Bulgaria',\n",
       " 'Cameroon',\n",
       " 'Guinea-Bissau',\n",
       " 'Panama',\n",
       " 'Guinea',\n",
       " 'Iran',\n",
       " 'Nicaragua',\n",
       " 'Georgia',\n",
       " 'Morocco',\n",
       " 'Madagascar',\n",
       " 'Fiji',\n",
       " 'South Africa',\n",
       " 'Djibouti',\n",
       " 'Liberia',\n",
       " 'Easter Island',\n",
       " 'Belarus',\n",
       " 'Colombia',\n",
       " 'Montenegro',\n",
       " 'DR Congo',\n",
       " 'Zimbabwe',\n",
       " 'Mozambique',\n",
       " 'Lithuania',\n",
       " 'Palau',\n",
       " 'United States',\n",
       " 'Kyrgyzstan',\n",
       " 'Laos',\n",
       " 'Venezuela',\n",
       " 'Eritrea',\n",
       " 'Bahamas',\n",
       " 'Angola',\n",
       " 'Somaliland',\n",
       " 'Estonia',\n",
       " 'Somalia',\n",
       " 'Latvia',\n",
       " 'Abkhazia',\n",
       " 'Vanuatu',\n",
       " 'Zambia',\n",
       " 'Sudan',\n",
       " 'Peru',\n",
       " 'Chile',\n",
       " 'Solomon Islands',\n",
       " 'Brazil',\n",
       " 'Sweden',\n",
       " 'Papua New Guinea',\n",
       " 'Niger',\n",
       " 'Bhutan',\n",
       " 'Uruguay',\n",
       " 'New Zealand',\n",
       " 'Algeria',\n",
       " 'Mali',\n",
       " 'Belize',\n",
       " 'Congo',\n",
       " 'South Sudan',\n",
       " 'Saudi Arabia',\n",
       " 'Finland',\n",
       " 'Argentina',\n",
       " 'South Ossetia',\n",
       " 'Paraguay',\n",
       " 'Oman',\n",
       " 'Chad',\n",
       " 'Norway',\n",
       " 'Turkmenistan',\n",
       " 'Bolivia',\n",
       " 'Central African Republic',\n",
       " 'Gabon',\n",
       " 'Russia',\n",
       " 'Niue',\n",
       " 'Kazakhstan',\n",
       " 'Mauritania',\n",
       " 'Botswana',\n",
       " 'Libya',\n",
       " 'Canada',\n",
       " 'Suriname',\n",
       " 'Guyana',\n",
       " 'Iceland',\n",
       " 'Australia',\n",
       " 'Namibia',\n",
       " 'Mongolia']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32678327",
   "metadata": {},
   "source": [
    "- Display for each country its rank, density, population, area. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a9623",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3525d8",
   "metadata": {},
   "source": [
    "- Save the information obtained in a Python dictionary. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b00cbf",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c31344",
   "metadata": {},
   "source": [
    "- Using the previously saved Python dictionary, ask the user for a country, display the \n",
    "corresponding information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d58996",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de123f",
   "metadata": {},
   "source": [
    "# Exercice 6 * - API Web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62855a4",
   "metadata": {},
   "source": [
    "- Write a Python program that will make available a Web API allowing elementary calculations on \n",
    "integers.\n",
    "\n",
    "The APIs are accessible by GET and in the form: \n",
    "- /add/{integer1}/{integer2}: add integer1 and integer2\n",
    "- /sub/{integer1}/{integer2}: perform the subtraction of integer1 and integer2\n",
    "- /mul/{integer1}/{integer2}: carry out the multiplication of integer1 and integer2\n",
    "- /div/{integer1}/{integer2}: perform the integer division of integer1 by integer2\n",
    "- /mod/{integer1}/{integer2}: perform the remainder of the integer division of integer1\n",
    "by integer2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad95976",
   "metadata": {},
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bcc6b6ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T07:03:46.583700Z",
     "start_time": "2024-10-11T07:03:36.825290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://localhost:8080\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [11/Oct/2024 09:03:41] \"GET /mod/42/8 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(host='localhost', port=8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3aae71",
   "metadata": {},
   "source": [
    "http://localhost:8080/mul/6/7\n",
    "\n",
    "http://localhost:8080/div/42/8\n",
    "\n",
    "http://localhost:8080/mod/42/8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ba86e6",
   "metadata": {},
   "source": [
    "- Write a Python program that will test the web API made available through the requests\n",
    "library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb9fd5f",
   "metadata": {},
   "source": [
    "Answer"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
